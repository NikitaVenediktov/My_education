{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лабораторная работа 4. DL на практике - Image Captioning (CV + NLP)\n",
    "\n",
    "Машинное обучение, часть 2, весна 2023\n",
    "\n",
    "В данной лабораторной вашей задачей будет построить простую модель для задачи Image Captioning - по изображению (image) сгенерировать текстовый заголовок (caption)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "0qol2g5d3phwmkp2vo807s",
    "execution_id": "10b039c8-66f9-4749-b8f6-4ae8ba23d883"
   },
   "source": [
    "# **Лабораторная работа 4**\n",
    "*Naumov Anton (Any0019)*\n",
    "\n",
    "*To contact me in telegram: @any0019*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "jk8t3bfh88p4gip9j3id",
    "execution_id": "fcc28013-d1ea-4210-b30f-7727ab22f1ca"
   },
   "source": [
    "В данном задании вашей задачей будет построить простую модель для задачи **Image Captioning** - по изображению (image) сгенерировать текстовый заголовок (caption)\n",
    "\n",
    "В ноутбуке будет несколько оцениваемых частей:\n",
    "1. **Подготовка данных для модели** (*4 балла*) --> требуется заполнить пропуски и составить пайплайн предобработки данных\n",
    "2. **Построение модели** (*3 балла*) --> требуется заполнить пропуски и составить пайплайн сборки модели\n",
    "3. **Обучение модели** (*3 балла*) --> требуется заполнить пропуски и составить пайплайн обучения модели\n",
    "4. **Оценка результатов** (*2 балл*) --> требуется заполнить пропуски и получить предсказания модели\n",
    "5. **Валидация качества** (*3+ баллов*) --> вам нужно будет обучить модель, чтобы превзойти определённые пороги на валидационной выборке\n",
    "\n",
    "**Структура данных:** \n",
    "- Вместе с заданием вам предложен файл __dataset.tar.gz__, в нём вы найдёте папку data, в которой присутствуют две папки с изображениями (**train** и **val**) в формате .png и два файла **captions_train.tsv** и **captions_val.tsv**\n",
    "- В файлах captions находятся таблицы с 6 полями, разделёнными через **\\t**, содержащими `img_id` (название файла с изображением в соответствующей папке) и `caption #1-#5` (5 текстовых заголовков для изображения __img_id__)\n",
    "- **ВАЖНО!!!** Не используйте val в обучении модели, только в тестах, т.к. часть баллов в конце ноутбука будет выдаваться в зависимости от результатов вашей модели на val выборке и если вы будете учиться на val срезе, то **баллы за всю лабораторную будут аннулированы**\n",
    "\n",
    "**Концепция простой модели**\n",
    "- Будем рассматривать задачу предсказания следующего слова в предложении, имея изображение и предыдущие слова\n",
    "- Для получения фичей из изображений будем использовать крупную свёрточную предобученную архитектуру\n",
    "- Для получения фичей из предыдущего текста будем использовать рекуррентную архитектуру с предобученными эмбеддингами\n",
    "- Сконкатенируем фичи по изображению и по тексту, чтобы получить финальный набор фичей\n",
    "- Классификатор, завершающийся линейным слоем к размеру словаря над финальным набором фичей\n",
    "- LogSoftmax + NLLLoss для оценки предсказания\n",
    "\n",
    "**Модели большие, подсчёты не быстрые - закладывайте время на обучение моделей**\n",
    "\n",
    "А так же в экспериментах обязательно подумайте можно ли как-то ускорить этот процесс?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "9jvseik14wk71g2wwaq3ug",
    "execution_id": "ca1aea67-7755-41c2-9713-f7b7fba7287d"
   },
   "source": [
    "------------------------------\n",
    "\n",
    "***Полезный комментарий:***\n",
    "\n",
    "*Местами, в коде вы будете встречать выполнение bash скриптов - их легко распознать по комментарию `#!g1.1:bash` вверху страницы.*\n",
    "\n",
    "*Если вы пользуетесь датосферой, то оставьте как есть, всё сработает, а вот если Google colab или что-то ещё, то замните код скриптов так, чтобы он начинался с `!`.*\n",
    "\n",
    "*К примеру:*\n",
    "\n",
    "*Изначальный блок:*\n",
    "```bash\n",
    "#!g1.1:bash\n",
    "ls -sh dataset.tar.gz\n",
    "```\n",
    "\n",
    "*Заменённый блок:*\n",
    "```bash\n",
    "!ls -sh dataset.tar.gz\n",
    "```\n",
    "\n",
    "------------------------------\n",
    "\n",
    "***Полезный комментарий 2:*** Местами в коде вы будете встречать `assert`-ы, их задача - помочь и подсказать вам, но если вы (в рамках экспериментов или просто сами) меняете что-то концептуально, то эти `assert`-ы могут перестать вас правильно проверять. Снимать баллы за подобное не будем, если сделанная вами логика... *кхэм*... логична :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "s89gqf90esoy0y0s6lgusf",
    "execution_id": "ea7b88d5-ae9e-4048-817a-260c4599c717"
   },
   "source": [
    "## 0. Скачиваем и распаковываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "72s9d8vmx14mhf5ip5cid"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
    "public_key = 'https://disk.yandex.ru/d/b84AkmdsYEpWNg'  # Сюда вписываете вашу ссылку\n",
    "\n",
    "# Получаем загрузочную ссылку\n",
    "final_url = base_url + urlencode(dict(public_key=public_key))\n",
    "response = requests.get(final_url)\n",
    "download_url = response.json()['href']\n",
    "\n",
    "# Загружаем файл и сохраняем его\n",
    "download_response = requests.get(download_url)\n",
    "with open('dataset.tar.gz', 'wb') as f:   # Здесь укажите нужный путь к файлу\n",
    "    f.write(download_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "6lc8kepcrfaawdaiicq8z",
    "execution_id": "478f1651-5962-4b1f-8dae-9f6025256433"
   },
   "source": [
    "## 1. Подготовка данных (***4 балла***)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "e0m5dp771bdh33aaleybr"
   },
   "outputs": [],
   "source": [
    "#!g1.1:bash\n",
    "ls -sh dataset.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "44s07i91esdf6su3dzydy8"
   },
   "outputs": [],
   "source": [
    "#!g1.1:bash\n",
    "# tar cfz dataset.tar.gz ./data\n",
    "tar xfz dataset.tar.gz -C ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "458ruqajt4bbd05hzaxj9m"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "vb3smxfxe8i1onq667fx0f"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "data_folder = \"./data\"\n",
    "\n",
    "dfs = dict()\n",
    "for split in ['train', 'val']:\n",
    "    dfs[split] = pd.read_csv(os.path.join(data_folder, f'captions_{split}.tsv'), sep='\\t')\n",
    "\n",
    "dfs['train'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "v5qwinuw6d1vnk6r2hx6"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "dfs['train'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "9kgn568oinho52gko0aik"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "dfs['val'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "nxxi93ojkqspdw063jxfi"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "# Для чтения изображений из файлов мы будем использовать библиотеку cv2 --> всё что вам нужно знать\n",
    "#   функция cv2.imread(path) принимает на вход путь к файлу изображения и возвращает np.array с изображением\n",
    "#   в порядке h x w x c\n",
    "image = cv2.imread(os.path.join(data_folder, 'train', '0001.png'))\n",
    "print(type(image))\n",
    "print(image.shape)\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "e6uhvmrb4rvzmh7iifb6u"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "inds = list(range(10))\n",
    "split = 'train'\n",
    "\n",
    "h, w = 2, 5\n",
    "title_width = 43\n",
    "\n",
    "assert h*w >= len(inds)\n",
    "\n",
    "fig, ax = plt.subplots(h, w, figsize=(20, 15))\n",
    "\n",
    "for i, ind in enumerate(inds):\n",
    "    row = dfs[split].iloc[ind]\n",
    "    img_id = row['img_id']\n",
    "    captions = [row[f'caption #{i}'] for i in range(5)]\n",
    "    \n",
    "    caption_adjasted = map(lambda el: '\\n'.join([(str(el[0]) + ': ' + el[1])[k:k+title_width] for k in range(0, 3 + len(el[1]), title_width)]), enumerate(captions))\n",
    "    caption = '\\n'.join(caption_adjasted)\n",
    "    plt.subplot(h, w, i+1)\n",
    "    plt.title(caption)\n",
    "    plt.imshow(cv2.imread(os.path.join(data_folder, split, img_id)))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "yaujznd4gtr816600r8rmk"
   },
   "source": [
    "### 1.2 Предобработка изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "573iruu84bg8f33goxk6n"
   },
   "source": [
    "**Сперва напишем предобработку для изображений**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "b72e3qg96vvvc1z36uxlub"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "zhtmjt6pxvafbqb4ame42"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Посчитайте поканальные mean и std для всех изображений из train (здесь можете так же использовать и val датасет)\n",
    "\n",
    "channel_mean = ...\n",
    "channel_std = ...\n",
    "\n",
    "print(channel_mean, channel_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ajgf8dcqmkiur5fcn1tynd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Напишите функцию для предобработки одного изображения\n",
    "\n",
    "image_prepare = tr.Compose([\n",
    "    tr.ToPILImage(),\n",
    "    # any transforms you want to add from \n",
    "    #   https://pytorch.org/vision/stable/transforms.html\n",
    "    ...\n",
    "    tr.ToTensor(),\n",
    "    tr.Normalize(channel_mean, channel_std)\n",
    "])\n",
    "\n",
    "# Sanity check\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "image = cv2.imread(os.path.join(data_folder, \"train\", \"0001.png\"))\n",
    "\n",
    "def de_normalize(img):\n",
    "    return minmax_scale(\n",
    "        (img.reshape(3, -1) + channel_mean[:, None]) * channel_std[:, None],\n",
    "        axis=1,\n",
    "    ).reshape(*img.shape)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(2, 4, figsize=(20, 8))\n",
    "for i in range(8):\n",
    "    plt.subplot(2, 4, i+1)\n",
    "    transformed_image = image_prepare(image).numpy().transpose(1, 2, 0)\n",
    "    plt.imshow(de_normalize(transformed_image))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ntgyvywgkhq8n4kw8m2uo3"
   },
   "source": [
    "### 1.3 Предобработка заголовков"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "83wlsl4e6riqlup3gh4yf"
   },
   "source": [
    "**Затем напишем предобработку для заголовков**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xpog1107mvivegx52yvw2d",
    "execution_id": "d5a48903-1cec-4a5c-8a9b-1873f654a37b"
   },
   "source": [
    "Для простоты вычислений предлагаю сделать крайне простую токенизацию, пользуясь регулярными выражениями и библиотекой **re**\n",
    "\n",
    "1. Приводим текст к нижнему регистру\n",
    "2. Заменяем всю пунктуацию на пробелы\n",
    "3. Убираем пробельные символы с концов строки\n",
    "4. Разбиваем по ненулевой последовательности пробельных символов\n",
    "5. Добавляем специальные токены \\<BOS> (begin of sentence) и \\<EOS> (end of sentence), чтобы обозначить границы заголовка для модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "h9hk3bpjfy84jg6s1etmgn"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "uir8tvlv9qq29ei0avg3xh",
    "execution_id": "5e85a9d2-7ebc-4a3e-9c10-ce72a2d9ba8b"
   },
   "source": [
    "Соберём словарь из всех слов, что встречаются в заголовках в train\n",
    "1. Токенизируем заголовки\n",
    "2. Обновляем частоту всех отдельных токенов\n",
    "3. Выкидываем все слова с частотой не больше минимума (допустим 3 - можете взять другое число) -> заменяем на специальный \\<UNK> (unknown) токен\n",
    "4. Записываем быстрое преобразование из токенов в индексы и наоборот"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "lgvmpv8nq478sjrkw7kpo"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from tqdm.notebook import trange\n",
    "from collections import Counter\n",
    "\n",
    "vocab_freq = Counter()\n",
    "\n",
    "# Параллельно заодно посчитаем длины заголовков в токенах (сколько раз встречалась какая длина в токенах) \n",
    "#   так же здесь можно использовать val при желании\n",
    "sizes = Counter()\n",
    "for i in trange(len(dfs['train'])):\n",
    "    ...\n",
    "\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "# !!!!!!!!ОБРАТИ ВНИМАНИЕ!!!!!!!!!\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "max_seq_len = np.max(list(sizes.keys()))\n",
    "# !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "\n",
    "show_ = 20\n",
    "fig, ax = plt.subplots(3, 1, figsize=(20, 12))\n",
    "\n",
    "plt.subplot(312)\n",
    "vocab_freq = {k: v for k, v in sorted(vocab_freq.items(), key=lambda item: item[1])}\n",
    "plt.title('least popular words')\n",
    "plt.bar(list(vocab_freq.keys())[:show_], list(vocab_freq.values())[:show_])\n",
    "\n",
    "plt.subplot(311)\n",
    "vocab_freq = {k: v for k, v in sorted(vocab_freq.items(), key=lambda item: item[1], reverse=True)}\n",
    "plt.title('most popular words')\n",
    "plt.bar(list(vocab_freq.keys())[:show_], list(vocab_freq.values())[:show_])\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.title('sequence sizes')\n",
    "plt.bar(list(sizes.keys()), list(sizes.values()))\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "kepravbotpxrj4skman8g"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Так же добавляем <PAD> токен для паддингов\n",
    "tok_to_ind = {\n",
    "    '<UNK>': 0,\n",
    "    '<BOS>': 1,\n",
    "    '<EOS>': 2,\n",
    "    '<PAD>': 3,\n",
    "}\n",
    "\n",
    "ind_to_tok = {\n",
    "    0: '<UNK>',\n",
    "    1: '<BOS>',\n",
    "    2: '<EOS>',\n",
    "    3: '<PAD>',\n",
    "}\n",
    "\n",
    "# Заполнить оставшееся\n",
    "...\n",
    "\n",
    "assert len(tok_to_ind) == len(ind_to_tok)\n",
    "vocab_size = len(tok_to_ind)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "1hhl4pik5fp4040p20u08s"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Функция возвращает по тексту индексы токенов в тексте\n",
    "def to_ids(text):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "fwx692w1ktg92xd7zpbwmf"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "text = \"Some random text I wrote. And the one, that cann't be forgotten unless I'll decide that... Tho it's still great\"\n",
    "toks = tokenize(text)\n",
    "ids = to_ids(text)\n",
    "print(toks)\n",
    "print(ids)\n",
    "assert toks[0] == '<BOS>' and toks[-1] == '<EOS>'\n",
    "assert ids[0] == tok_to_ind['<BOS>'] and ids[-1] == tok_to_ind['<EOS>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xxcu5ctdfz233tyafpj1u"
   },
   "source": [
    "### 1.4 Датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "upzb9xjar21r1cqy8zjnt"
   },
   "source": [
    "**Сделаем класс датасета в стиле torch.utils.data.Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "amlltts14prhvc45zm61i9"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "import torch\n",
    "\n",
    "class ImageCaptioningDataset(Dataset):\n",
    "    \"\"\"\n",
    "        imgs_path ~ путь к папке с изображениями\n",
    "        captions_path ~ путь к .tsv файлу с заголовками изображений\n",
    "    \"\"\"\n",
    "    def __init__(self, imgs_path, captions_path):\n",
    "        super(ImageCaptioningDataset).__init__()\n",
    "        # Читаем и записываем из файлов в память класса, чтобы быстро обращаться внутри датасета\n",
    "        # Если не хватает памяти на хранение всех изображений, то подгружайте прямо во время __getitem__, но это замедлит обучение\n",
    "        # Проведите всю предобработку, которую можно провести без потери вариативности датасета, здесь\n",
    "        ...\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        ...\n",
    "        \n",
    "        # Получаем предобработанное изображение\n",
    "        ...\n",
    "        \n",
    "        # Получаем по каждому заголовку набор in текстов - out слов\n",
    "        #   в каждом заголовке берём всевозможные не пустые префиксы как in и следующее за префиксом слово как out\n",
    "        #   применяем padding ко всем текстам в in (слева или справа?)\n",
    "        #   in_seqs: torch.tensor \\in [\\sum{len(caption_i) - 1}; max_seq_len or local_max_seq_len]\n",
    "        #   out_words: torch.tensor \\in [\\sum{len(caption_i) - 1}]\n",
    "        ...\n",
    "        \n",
    "        return img, in_seqs, out_words\n",
    "    \n",
    "    def __len__(self):\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "hr1yjxjlh462dzuavnjj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "ds_train = ImageCaptioningDataset(os.path.join(data_folder, 'train'), os.path.join(data_folder, f'captions_train.tsv'))\n",
    "ds_val = ImageCaptioningDataset(os.path.join(data_folder, 'val'), os.path.join(data_folder, f'captions_val.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "skxtz0k40v01d463pe3jou"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "img_, in_seqs_, out_words_ = ds_train[0]\n",
    "\n",
    "assert isinstance(img_, torch.Tensor)\n",
    "assert isinstance(in_seqs_, torch.Tensor)\n",
    "assert isinstance(out_words_, torch.Tensor)\n",
    "\n",
    "assert img_.shape[0] == 3\n",
    "assert in_seqs_.shape[0] == out_words_.shape[0]\n",
    "assert ind_to_tok[out_words_[-1].item()] == \"<EOS>\"\n",
    "\n",
    "assert ds_train.__len__() == len(os.listdir(os.path.join(data_folder, 'train')))\n",
    "assert ds_val.__len__() == len(os.listdir(os.path.join(data_folder, 'val')))\n",
    "\n",
    "print(img_.shape)\n",
    "print(in_seqs_.shape)\n",
    "print(out_words_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "8y7ewpjb8v920hrn0e9p19"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Sanity check\n",
    "plt.imshow(\n",
    "    de_normalize(img_.numpy().transpose(1, 2, 0))\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "9zvup5kf0njmr8mswa6mjg"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Только если вы возвращаете сразу группу, если вы возвращаете в __getitem__ один элемент, то просто игнорируйте этот блок\n",
    "k = 10\n",
    "\n",
    "# Для паддингов справа\n",
    "# Здесь должна быть лесенка, если вы не перемешиваете дополнительно зачем-то in_seqs в __getitem__\n",
    "print(in_seqs_[:k+1,:k+1].numpy())\n",
    "print('\\n')\n",
    "# А тут вы должны узнать эти числа из матрицы выше\n",
    "print('    ', out_words_[:k].numpy())\n",
    "\n",
    "\n",
    "# Для паддингов слева\n",
    "# Здесь должна быть лесенка\n",
    "print(in_seqs_[:k+1,-k-1:].numpy())\n",
    "print('\\n')\n",
    "# А тут вы должны узнать эти числа из матрицы выше\n",
    "print('    ', out_words_[-k:].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "a58dayy93gjik14bml66v9"
   },
   "source": [
    "### 1.5 Даталоадер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "xgjy1gdmzf8imgku7ree7a"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Сложим батч в следующем виде:\n",
    "#   img_batch: [bs, c, h, w]\n",
    "#   in_seqs_batch: [\\sum_{i \\in range(bs)}(\\sum(seq_lens)_i), max_seq_len or local_max_seq_len]\n",
    "#   out_words_batch: [\\sum_{i \\in range(bs)}(\\sum(seq_lens)_i)]\n",
    "#   text_to_image_align: [bs] --> число строк в in_seqs_batch и out_seqs_batch, соответствующих картинке\n",
    "\n",
    "def collate_fn(batch):\n",
    "    ...\n",
    "    return img_batch, in_seqs_batch, out_words_batch, text_to_image_align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ibp7abd576q0xx46k10zz0k"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "batch_size = 32\n",
    "\n",
    "dataloader_train = DataLoader(\n",
    "    dataset=ds_train,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "dataloader_val = DataLoader(\n",
    "    dataset=ds_val,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=collate_fn,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "cu7pbmxv37hipll7777wf"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "img_batch, in_seqs_batch, out_words_batch, text_to_image_align = next(iter(dataloader_train))\n",
    "\n",
    "assert isinstance(img_batch, torch.Tensor)\n",
    "assert isinstance(in_seqs_batch, torch.Tensor)\n",
    "assert isinstance(out_words_batch, torch.Tensor)\n",
    "assert isinstance(text_to_image_align, torch.Tensor)\n",
    "\n",
    "assert img_batch.shape[:2] == torch.Size([batch_size, 3])\n",
    "assert in_seqs_batch.shape[0] == out_words_batch.shape[0]\n",
    "assert text_to_image_align.shape[0] == batch_size\n",
    "assert text_to_image_align.sum() == in_seqs_batch.shape[0]\n",
    "\n",
    "assert in_seqs_batch.dtype in {torch.int64, torch.LongTensor}\n",
    "assert out_words_batch.dtype in {torch.int64, torch.LongTensor}\n",
    "assert text_to_image_align.dtype in {torch.int64, torch.LongTensor}\n",
    "\n",
    "print(img_batch.shape, in_seqs_batch.shape, out_words_batch.shape, text_to_image_align.shape, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "cw2vcmul7261h2ipvuhhf4",
    "execution_id": "9dce1b0e-14af-409f-845a-7904b688a675"
   },
   "source": [
    "## 2. Составляем модель (***3 балла***)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ixxcxsyeq5orhsyh40ypr",
    "execution_id": "04fce580-799c-4f77-b36a-af094df01c4a"
   },
   "source": [
    "Если картинка не появляется, то откройте блок и перейдите по ссылке внутри.\n",
    "\n",
    "![модель](лаба1_модель.png \"Модель\")\n",
    "\n",
    "<img src=https://disk.yandex.ru/i/ZvTuLzSe4TGWmQ alt=\"Модель\" width=\"30%\" height=\"200\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "y92usx83bnb5zp3qip6a15"
   },
   "source": [
    "### 2.1 Фича-экстрактор для изображений"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "w8ymxl1w1cf1q4nugxn4n"
   },
   "source": [
    "Возьмите какую-нибудь предобученную модель (к примеру resnet), по желанию заморозьте все или часть слоёв, наиболее вероятно уберите последний слой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "x22s6ju2nyaf7wzq301eva"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from torchvision import models\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "qh3qk4xr9q130okh60u59a"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class img_fe_class(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(img_fe_class, self).__init__()\n",
    "        self.img_fe = ...\n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        return self.img_fe(imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ho5hu57qch9rwbezi07yz"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "img_fe = img_fe_class()\n",
    "    \n",
    "feat_img = img_fe(img_[None,:,:,:])\n",
    "\n",
    "assert len(feat_img.shape) == 2\n",
    "assert feat_img.shape[0] == 1\n",
    "\n",
    "print(f'outputs {feat_img.shape[1]} features from feature extractor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "3okjqfglghe65rxjkhcj5t"
   },
   "source": [
    "### 2.2 Фича-экстрактор для текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "twueftwg4b6oodu4roj6c",
    "execution_id": "9a0c4261-6372-4aec-b25d-e3627bad4720"
   },
   "source": [
    "Давайте скачаем предобученные glove вектора и инициализируем nn.Embedding ими, там где мы их знаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "28xxgrbk20boyf98zvj7i9"
   },
   "outputs": [],
   "source": [
    "#!g1.1:bash\n",
    "wget -O glove.zip https://huggingface.co/stanfordnlp/glove/resolve/main/glove.840B.300d.zip\n",
    "\n",
    "# mirror https://nlp.stanford.edu/data/wordvecs/glove.840B.300d.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "sthazxfezmn48z64ivb0xi"
   },
   "outputs": [],
   "source": [
    "#!g1.1:bash\n",
    "unzip glove.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "asfj2084cbazlcfj3vu6c9"
   },
   "outputs": [],
   "source": [
    "#!g1.1:bash\n",
    "ls -sh glove.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "bzkg45inz9c8zhrit7f9y"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# Открываем glove\n",
    "np.random.seed(19)\n",
    "\n",
    "def load_glove_weights(file_path, vocab, pad_token=\"<PAD>\"):\n",
    "    print(\"Loading Glove Weights\")\n",
    "    # Инициализируем веса для всех слов стандартным нормальным распределением\n",
    "    glove_weights = np.random.uniform(0, 1, (len(vocab), 300))\n",
    "    mask_found = np.zeros(len(vocab), dtype=bool)\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in tqdm(f, total=2196018):\n",
    "            line = line.split()\n",
    "            token = ' '.join(line[:-300])\n",
    "            embed = line[-300:]\n",
    "\n",
    "            if token in vocab:\n",
    "                ind = vocab[token]\n",
    "                mask_found[ind] = True\n",
    "                glove_weights[ind, :] = np.array(list(map(float, embed)), dtype=np.float)\n",
    "\n",
    "    print(f\"{mask_found.sum()} words from vocab of size {len(vocab)} loaded!\")\n",
    "\n",
    "    glove_weights[vocab[pad_token]] = np.zeros(300, dtype=np.float)\n",
    "    return glove_weights, mask_found\n",
    "\n",
    "\n",
    "glove_path = \"./glove.840B.300d.txt\"\n",
    "glove_weights, mask_found = load_glove_weights(glove_path, tok_to_ind, \"<PAD>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "iieb90aa3yqh9h8f7zaii"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "class text_fe_class(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(text_fe_class, self).__init__()\n",
    "        self.embed = nn.Embedding(...)\n",
    "        self.embed.weight = nn.Parameter(...)\n",
    "\n",
    "        ...\n",
    "        \n",
    "    def forward(self, in_seqs):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "c63jp4cbtoorr1jyym2wnm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "text_fe = text_fe_class()\n",
    "feat_text = text_fe(in_seqs_)\n",
    "\n",
    "assert in_seqs_.shape[0] == feat_text.shape[0]\n",
    "assert len(feat_text.shape) == 2, 'По каждому тексту вам нужен один вектор, а RNN блок возвращает output для каждого шага seq_len, не забудьте как-то это исправить'\n",
    "\n",
    "print(in_seqs_.shape)\n",
    "print(feat_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "flnbv9uwq6qgzshqfrnus"
   },
   "source": [
    "### 2.3 Финальная модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xhv7rcxureje8uz9phnq",
    "execution_id": "25e3154f-1772-4ec5-ae1a-6c106ca106fe"
   },
   "source": [
    "Сконкатенируйте полученные фичи и подайте в линейный слой (лучше сделать хотя 2 линейных слоя для большей гибкости).\n",
    "\n",
    "Так же подумайте какие ещё блоки / слои тут могут быть нужны."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "mk0g1k22smb9ubu2pno0pj"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from collections import OrderedDict\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "class image_captioning_model(nn.Module):\n",
    "    def __init__(self, img_fe, text_fe, device=device, ...):\n",
    "        super(image_captioning_model, self).__init__()\n",
    "        self.img_fe = img_fe\n",
    "        self.text_fe = text_fe\n",
    "        self.device = device\n",
    "        ...\n",
    "        \n",
    "        self.fc = nn.Sequential(OrderedDict([\n",
    "            ('in2hid', nn.Linear(1024, hid_size)),\n",
    "            ('act', nn.ReLU()),\n",
    "            ('drop', nn.Dropout(dropout_p)),\n",
    "            ('bnorm', nn.BatchNorm1d(hid_size)),\n",
    "            ('hid2out', nn.Linear(hid_size, vocab_size)),\n",
    "            ('log_soft', nn.LogSoftmax(dim=-1)),\n",
    "        ]))\n",
    "        \n",
    "    def forward(self, img_batch, in_seqs_batch, text_to_image_align):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "06hl0s2t9k4xoiqb6ry03i"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "model = image_captioning_model(img_fe, text_fe).float().to(device)\n",
    "\n",
    "res = model(img_batch, in_seqs_batch, text_to_image_align)\n",
    "\n",
    "assert res.shape[0] == np.sum(out_words_batch.shape[0])\n",
    "assert res.shape[1] == vocab_size\n",
    "\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "jnpoagcrohh9jaz2jco0b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from termcolor import colored\n",
    "\n",
    "def beautiful_int(i):\n",
    "    i = str(i)\n",
    "    return \".\".join(reversed([i[max(j, 0):j+3] for j in range(len(i) - 3, -3, -3)]))\n",
    "\n",
    "# Считаем общее число параметров в нашей модели\n",
    "def model_num_params(model, verbose_all=True, verbose_only_learnable=False):\n",
    "    sum_params = 0\n",
    "    sum_learnable_params = 0\n",
    "    for param in model.named_parameters():\n",
    "        num_params = np.prod(param[1].shape)\n",
    "        if verbose_all or (verbose_only_learnable and param[1].requires_grad):\n",
    "            print(\n",
    "                colored(\n",
    "                    '{: <42} ~  {: <9} params ~ grad: {}'.format(\n",
    "                        param[0],\n",
    "                        beautiful_int(num_params),\n",
    "                        param[1].requires_grad,\n",
    "                    ),\n",
    "                    {True: \"green\", False: \"red\"}[param[1].requires_grad],\n",
    "                )\n",
    "            )\n",
    "        sum_params += num_params\n",
    "        if param[1].requires_grad:\n",
    "            sum_learnable_params += num_params\n",
    "    print(\n",
    "        f'\\nIn total:\\n  - {beautiful_int(sum_params)} params\\n  - {beautiful_int(sum_learnable_params)} learnable params'\n",
    "    )\n",
    "    return sum_params, sum_learnable_params\n",
    "\n",
    "\n",
    "sum_params, sum_learnable_params = model_num_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "x10a7wm1m4j9ep99gz8y3a",
    "execution_id": "a60a3d7a-5015-42a6-b1a1-28ea81ba5647"
   },
   "source": [
    "## 3. Пайплайн обучения (***3 балла***)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "rfmzra7hz28zqm3cj2vv6"
   },
   "source": [
    "### 3.1 Оптимайзер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "1p9n5u1z2a90943yahtgkpn"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def create_model_and_optimizer(model_class, model_params, ..., device=device):\n",
    "    model = model_class(**model_params)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    optimizer = ...\n",
    "    return model, optimizer\n",
    "\n",
    "# Убедитесь что всё сработало и создалось нормально и без ошибок\n",
    "model, optimizer = create_model_and_optimizer(\n",
    "    ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "8ss4qmu9tiuz305c4ppe7t"
   },
   "source": [
    "### 3.2 Один шаг обучения/валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "zwblqwgw1g8c97zamvy4y"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from collections import defaultdict\n",
    "\n",
    "def train(model, opt, loader, criterion):\n",
    "    model.train()\n",
    "    losses_tr = []\n",
    "    for img_batch, in_seqs_batch, out_words_batch, text_to_image_align in tqdm(loader):\n",
    "        optimizer.zero_grad()\n",
    "        pred = ...\n",
    "        loss = ...\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses_tr.append(loss.item())\n",
    "    \n",
    "    return model, optimizer, np.mean(losses_tr)\n",
    "\n",
    "\n",
    "def val(model, loader, criterion, metric_names=None):\n",
    "    model.eval()\n",
    "    losses_val = []\n",
    "    if metric_names is not None:\n",
    "        metrics = defaultdict(list)\n",
    "    with torch.no_grad():\n",
    "        for img_batch, in_seqs_batch, out_words_batch, text_to_image_align in tqdm(loader):\n",
    "            pred = ...\n",
    "            loss = ...\n",
    "\n",
    "            losses_val.append(loss.item())\n",
    "            \n",
    "            # Можете добавить сюда любые метрики, которые хочется (см. код здесь и 3.3 за подробностями)\n",
    "            if metric_names is not None:\n",
    "                if 'accuracy' in metric_names:\n",
    "                    preds = torch.argsort(pred, dim=1, descending=True)\n",
    "                    for k in metric_names[\"accuracy\"][\"top\"]:\n",
    "                        metrics[f'accuracy ~ top#{k}'].append(\n",
    "                            np.mean([out_words_batch[i].item() in preds[i, :k] for i in range(out_words_batch.shape[0])])\n",
    "                        )\n",
    "\n",
    "        if metric_names is not None:\n",
    "            for name in metrics:\n",
    "                metrics[name] = np.mean(metrics[name])\n",
    "    \n",
    "    return np.mean(losses_val), metrics if metric_names else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "hqv3jmnfx7o2ep9obsjt5"
   },
   "source": [
    "### 3.3 Цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "jn68d89hk6yv3ghn46vg"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "\n",
    "def learning_loop(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    scheduler=None,\n",
    "    min_lr=None,\n",
    "    epochs=10,\n",
    "    val_every=1,\n",
    "    draw_every=1,\n",
    "    separate_show=False,\n",
    "    model_name=None,\n",
    "    chkp_folder=\"./chkps\",\n",
    "    metric_names=None,\n",
    "    save_only_best=True,\n",
    "):\n",
    "    if model_name is None:\n",
    "        if os.exists(chkp_folder):\n",
    "            num_starts = len(os.listdir(chkp_folder)) + 1\n",
    "        else:\n",
    "            num_starts = 1\n",
    "        model_name = f'model#{num_starts}'\n",
    "    \n",
    "    if os.exists(os.path.join(chkp_folder, model_name)):\n",
    "        model_name = model_name + \"_v2\"\n",
    "        warnings.warn(f\"Selected model_name was used already! To avoid possible overwrite - model_name changed to {model_name}\")\n",
    "    os.makedirs(os.path.join(chkp_folder, model_name))\n",
    "    \n",
    "    losses = {'train': [], 'val': []}\n",
    "    lrs = []\n",
    "    best_val_loss = np.Inf\n",
    "    if metric_names is not None:\n",
    "        metrics = defaultdict(list)\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print(f'#{epoch}/{epochs}:')\n",
    "\n",
    "        lrs.append(get_lr(optimizer))\n",
    "        \n",
    "        model, optimizer, loss = train(model, optimizer, train_loader, criterion)\n",
    "        losses['train'].append(loss)\n",
    "\n",
    "        if not (epoch % val_every):\n",
    "            loss, metrics_ = val(model, val_loader, criterion, metric_names=metric_names)\n",
    "            losses['val'].append(loss)\n",
    "            if metrics_ is not None:\n",
    "                for name, value in metrics_.items():\n",
    "                    metrics[name].append(value)\n",
    "            \n",
    "            # Сохраняем лучшую по валидации модель\n",
    "            if ((not save_only_best) or (loss < best_val_loss)):\n",
    "                if not os.path.exists(chkp_folder):\n",
    "                    os.makedirs(chkp_folder)\n",
    "                torch.save(\n",
    "                    {\n",
    "                        'epoch': epoch,\n",
    "                        'model_state_dict': model.state_dict(),\n",
    "                        'optimizer_state_dict': optimizer.state_dict(),\n",
    "                        'scheduler_state_dict': scheduler.state_dict(),\n",
    "                        'losses': losses,\n",
    "                    },\n",
    "                    os.path.join('./checkpoints', model_name, f'{model_name}#{epoch}.pt'),\n",
    "                )\n",
    "                best_val_loss = loss\n",
    "            \n",
    "            if scheduler:\n",
    "                try:\n",
    "                    scheduler.step()\n",
    "                except:\n",
    "                    scheduler.step(loss)\n",
    "\n",
    "        if not (epoch % draw_every):\n",
    "            clear_output(True)\n",
    "            ww = 3 if separate_show else 2\n",
    "            ww_metrics = 0\n",
    "            if metric_names is not None:\n",
    "                plot_ids_ = [\n",
    "                    [key, metric_meta.get(\"plot id\", 1)]\n",
    "                    for key, metric_meta\n",
    "                    in metric_names.items()\n",
    "                ]\n",
    "                ww_metrics = len(set(el[1] for el in plot_ids_))\n",
    "                assert all(el[1] <= ww_metrics for el in plot_ids_)\n",
    "                \n",
    "                plot_ids = defaultdict(list)\n",
    "                for el in plot_ids_:\n",
    "                    plot_ids[el[1]].append(el[0])\n",
    "                \n",
    "            fig, ax = plt.subplots(1, ww + ww_metrics, figsize=(20, 10))\n",
    "            fig.suptitle(f'#{epoch}/{epochs}:')\n",
    "\n",
    "            plt.subplot(1, ww + ww_metrics, 1)\n",
    "            plt.plot(losses['train'], 'r.-', label='train')\n",
    "            if separate_show:\n",
    "                plt.title('loss on train')\n",
    "                plt.legend()\n",
    "            plt.grid()\n",
    "\n",
    "            if separate_show:\n",
    "                plt.subplot(1, ww + ww_metrics, 2)\n",
    "                plt.title('loss on validation')\n",
    "                plt.grid()\n",
    "            else:\n",
    "                plt.title('losses')\n",
    "            plt.plot(losses['val'], 'g.-', label='val')\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.subplot(1, ww + ww_metrics, ww)\n",
    "            plt.title('learning rate')\n",
    "            plt.plot(lrs, 'g.-', label='lr')\n",
    "            plt.legend()\n",
    "            plt.grid()\n",
    "            \n",
    "            if metric_names is not None:\n",
    "                for plot_id, keys in plot_ids.items():\n",
    "                    for key in keys:\n",
    "                        plt.subplot(1, ww + ww_metrics, ww + plot_id)\n",
    "                        plt.title(f'additional metrics #{plot_id}')\n",
    "                        for name in metrics:\n",
    "                            if key in name:\n",
    "                                plt.plot(metrics[name], '.-', label=name)\n",
    "                        plt.legend()\n",
    "                        plt.grid()\n",
    "            \n",
    "            plt.show()\n",
    "        \n",
    "        if min_lr and get_lr(optimizer) <= min_lr:\n",
    "            print(f'Learning process ended with early stop after epoch {epoch}')\n",
    "            break\n",
    "    \n",
    "    return model, optimizer, losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "dd1po7rfl5m3d6o6xl34yt",
    "execution_id": "374b479c-7b61-4694-9894-ed892a610205"
   },
   "source": [
    "### 3.4 Обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "ncv9w5pmuof8ebnsc3xdep"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "%%time\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "img_fe = img_fe_class()\n",
    "text_fe = text_fe_class()\n",
    "\n",
    "model, optimizer = create_model_and_optimizer(\n",
    "    model_class = image_captioning_model,\n",
    "    model_params = {\n",
    "        'img_fe': img_fe,\n",
    "        'text_fe': text_fe,\n",
    "        'hid_size': 1024,\n",
    "        'dropout_p': 0.3,\n",
    "    },\n",
    "    lr = 1e-3,\n",
    "    device = device,\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.25, patience=4, threshold=0.001, verbose=True)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "model, optimizer, losses = learning_loop(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    train_loader = dataloader_train,\n",
    "    val_loader = dataloader_val,\n",
    "    criterion = criterion,\n",
    "    scheduler = scheduler,\n",
    "    epochs = 100,\n",
    "    min_lr = 1e-6,\n",
    "    val_every = 1,\n",
    "    draw_every = 1,\n",
    "    separate_show = False,\n",
    "    metric_names = {\n",
    "        \"accuracy\": {\"top\": [1, 5], \"plot_id\": 1},\n",
    "    },\n",
    "    chkp_folder = \"./chkp\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "9m6p1o20os3rvuman6s7c"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "%%time\n",
    "\n",
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "img_fe = ...\n",
    "text_fe = ...\n",
    "\n",
    "model, optimizer = create_model_and_optimizer(\n",
    "    ...\n",
    ")\n",
    "\n",
    "scheduler = ...\n",
    "\n",
    "criterion = ...\n",
    "\n",
    "model, optimizer, losses = learning_loop(\n",
    "    model = model,\n",
    "    optimizer = optimizer,\n",
    "    train_loader = dataloader_train,\n",
    "    val_loader = dataloader_val,\n",
    "    criterion = criterion,\n",
    "    scheduler = scheduler,\n",
    "    epochs = 100,\n",
    "    min_lr = 1e-6,\n",
    "    val_every = 1,\n",
    "    draw_every = 1,\n",
    "    separate_show = False,\n",
    "    metric_names = {\n",
    "        \"accuracy\": {\"top\": [1, 5], \"plot_id\": 1},\n",
    "    },\n",
    "    chkp_folder = \"./chkp\",\n",
    "    model_name = \"left_pad\",\n",
    "    save_only_best=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "ppwwtmipqwgk3smnigxh8"
   },
   "source": [
    "### 3.5 Загрузка чекпоинта"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "24do65l9uc3c1en9puqp"
   },
   "source": [
    "#### **Не запускайте этот блок, если не понимаете для чего это в данную секунду!**\n",
    "\n",
    "#### **Так можно случайно перезатереть несколько часов вычислений, если не скопировать их в отдельную переменную/чекпоинт**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "b3cofy2t6del4sktn51mwm"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "assert False, \"Are you sure? If not - stop right here, otherwise - comment this assert line\"\n",
    "\n",
    "\n",
    "chkp_folder = ...\n",
    "model_name = ...\n",
    "epoch = ...\n",
    "checkpoint = torch.load(os.path.join(chkp_folder, model_name, f'{model_name}#{epoch}.pt'))\n",
    "\n",
    "# Создаём те же классы, что и внутри чекпоинта\n",
    "model, optimizer = create_model_and_optimizer(\n",
    "    ...\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.25, patience=4, threshold=0.001, verbose=True)\n",
    "\n",
    "# Загружаем состояния из чекпоинта\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "losses = checkpoint['losses']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "j29u0qg4jm9uo4sb5009zq",
    "execution_id": "71a59fd7-d8b2-4941-a734-6131e5e54eb0"
   },
   "source": [
    "## 4. Оценка результатов (***2 балл***)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "xscbzlik3ghdvsntx4r5q7"
   },
   "source": [
    "### 4.1 Генерация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "t0elwvv6f9cvb3ft4030c"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from typing import Optional\n",
    "\n",
    "def generate(\n",
    "    model,\n",
    "    image,\n",
    "    max_seq_len: Optional[int] = max_seq_len,\n",
    "    top_p: Optional[float] = None,\n",
    "    top_k: Optional[int] = None,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    По картинке image генерируете текст моделью model либо пока не сгенерируете '<EOS>' токен, либо пока не сгенерируете max_seq_len токенов\n",
    "        top_k -> после получения предсказания оставляете первые top_k слов и сэмплируете случайно с перенормированными вероятностями из оставшихся слов\n",
    "        top_p -> после получения предсказания оставляете первые сколько-то слов, так, чтобы суммарная вероятность оставшихся слов была не больше top_p,\n",
    "            после чего сэмплируете с перенормированными вероятностями из оставшихся слов\n",
    "        иначе -> сэмплируете случайное слово с предсказанными вероятностями\n",
    "    \"\"\"\n",
    "    assert top_p is None or top_k is None, \"Don't use top_p and top_k at the same time\"\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "is9vm1z9qy7w0bwyc4p7",
    "execution_id": "54565491-9f72-46ca-9e05-4018dcf53535"
   },
   "source": [
    "### 4.2 Посмотрим на предсказания модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "8v6ghj16vdru7mzqhsodsd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "inds = list(range(10))\n",
    "split = 'train'\n",
    "\n",
    "h, w = 2, 5\n",
    "title_width = 43\n",
    "\n",
    "assert h*w >= len(inds)\n",
    "\n",
    "fig, ax = plt.subplots(h, w, figsize=(20, 15))\n",
    "\n",
    "for i, ind in enumerate(inds):\n",
    "    row = dfs[split].iloc[ind]\n",
    "    img_id = row['img_id']\n",
    "    img = cv2.imread(os.path.join(data_folder, split, img_id))\n",
    "    \n",
    "    pred_caption = generate(model, img, max_seq_len=..., top_p=..., top_k=...)\n",
    "    pred_caption = '\\n'.join([pred_caption[k:k+title_width] for k in range(0, len(pred_caption), title_width)])\n",
    "    \n",
    "    captions = [row[f'caption #{i}'] for i in range(5)]\n",
    "    caption_adjasted = list(map(lambda el: '\\n'.join([(str(el[0]) + ': ' + el[1])[k:k+title_width] for k in range(0, 3 + len(el[1]), title_width)]), enumerate(captions)))\n",
    "    \n",
    "    caption = '\\n'.join(['pred:\\n' + pred_caption + '\\n\\n'] + caption_adjasted)\n",
    "    \n",
    "    plt.subplot(h, w, i+1)\n",
    "    plt.title(caption)\n",
    "    plt.imshow(img)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "7l3qdo5j4uwl46mr44brvk"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "inds = list(range(10))\n",
    "split = 'val'\n",
    "\n",
    "h, w = 2, 5\n",
    "title_width = 43\n",
    "\n",
    "top_p = None\n",
    "top_k = 3\n",
    "\n",
    "assert h*w >= len(inds)\n",
    "\n",
    "fig, ax = plt.subplots(h, w, figsize=(20, 15))\n",
    "\n",
    "for i, ind in enumerate(inds):\n",
    "    row = dfs[split].iloc[ind]\n",
    "    img_id = row['img_id']\n",
    "    img = cv2.imread(os.path.join(data_folder, split, img_id))\n",
    "    \n",
    "    pred_caption = generate(model, img, max_seq_len=..., top_p=..., top_k=...)\n",
    "    pred_caption = '\\n'.join([pred_caption[k:k+title_width] for k in range(0, len(pred_caption), title_width)])\n",
    "    \n",
    "    captions = [row[f'caption #{i}'] for i in range(5)]\n",
    "    caption_adjasted = list(map(lambda el: '\\n'.join([(str(el[0]) + ': ' + el[1])[k:k+title_width] for k in range(0, 3 + len(el[1]), title_width)]), enumerate(captions)))\n",
    "    \n",
    "    caption = '\\n'.join(['pred:\\n' + pred_caption + '\\n\\n'] + caption_adjasted)\n",
    "    \n",
    "    plt.subplot(h, w, i+1)\n",
    "    plt.title(caption)\n",
    "    plt.imshow(img)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "d3ohcelofuhe3t0wx8ju3h"
   },
   "source": [
    "### 4.3 BLEU на всём val датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "lsqv4dvg7xsoqie6id0ug"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "from torchtext.data.metrics import bleu_score\n",
    "\n",
    "def get_bleu(model, max_seq_len=max_seq_len, top_p=None, top_k=None, split=\"val\"):\n",
    "    candidates = []\n",
    "    references = []\n",
    "    ...\n",
    "\n",
    "    return bleu_score(candidates, references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "4r1ff381azwdqp56sdqqd"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n",
    "# При сдаче задания - напишите в комментарий к работе свой скор из вот этой ячейки\n",
    "bleu_res = get_bleu(model, max_seq_len=..., top_p=..., top_k=..., split=\"val\")\n",
    "print(bleu_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "7hxkzdv19uobw6u30cjb",
    "execution_id": "d4e2d43d-99dd-43af-b9bc-7bf791670071"
   },
   "source": [
    "## 5. Эксперименты (***3+ баллов***)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cellId": "w6j0hab0z2m0b5nkp4eqs",
    "execution_id": "1b404869-7f0f-4eee-8f7d-aa6791514139"
   },
   "source": [
    "В этой части у вас не будет никакого написанного мною кода, а всё что вы здесь будете делать - на ваше усмотрение и по вашей задумке\n",
    "\n",
    "Цель эксперментов:\n",
    "**Пройти порог BLEU score на валидации (только делайте это честно, если где-то валидация будет протекать в обучение - 0 баллов за всё задание не думая)**\n",
    "\n",
    "В блоке 4.3 при подсчёте BLEU на Val датасете вам нужно преодолеть следующие пороги:\n",
    "\n",
    "**0.1** --> **1 балл**\n",
    "\n",
    "**0.2** --> **2 балла**\n",
    "\n",
    "**0.25** --> **3 балла**\n",
    "\n",
    "В зависимости от решений других студентов пороги могут измениться, а за самые лучшие решения мы можем добавить дополнительные баллы. Эти дополнительные баллы не могут перейти на другие домашки, но могут помочь компенсировать потерянные в ходе именно этой лабораторной баллы в других частях.\n",
    "\n",
    "**Так же важно:**\n",
    "1. Процесс обучения данной модели должен находиться в данном ноутбуке в разделах 1-5, чтобы мы видели что чекпоинт правда ваш и написан/обучен вами.\n",
    "2. Все эксперименты должны быть задокументированы: что вы пробовали, почему, какие результаты получили. Старайтесь максимально качественно описывать все свои эксперименты, потому что за отсутствие или за низкого качества описания экспериментов могут сниматься баллы. \n",
    "\n",
    "___Рисуйте графики, таблицы, не забывайте про то, что несколько графиков можно уместить в одном поле вывода, подписывайте оси, пишите заголовки.___\n",
    "\n",
    "___Простой тест для самих себя - откройте свой ноутбук и дальше читайте только markdown-поля и выводы ячеек, но не сами ячейки с кодом.___\n",
    "\n",
    "___Если, сделав это, вы не смогли понять что делалось в ноутбуке и какие результаты были получены - что-то явно не так и такого рода работа точно является кандидатом под снижение баллов за оформление и документацию экспериментов.___\n",
    "\n",
    "___Так же старайтесь сделать оформление работы чистым при сдаче - мы можем снизить баллы, если общее качество оформления будет низким, т.к. проверять работы мы будем вручную.___\n",
    "\n",
    "\n",
    "### **Удачи!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellId": "db54o3dw3b5ddeygdutp75"
   },
   "outputs": [],
   "source": [
    "#!g1.1\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "notebookId": "17363971-719b-4854-a6ec-adfa361d241d",
  "notebookPath": "Lab1 - CV + NLP/lab4_master-Copy1.ipynb",
  "ydsNotebookPath": "Lab1 - CV + NLP/lab1_master.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
