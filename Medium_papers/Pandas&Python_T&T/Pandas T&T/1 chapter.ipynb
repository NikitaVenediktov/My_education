{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas tricks & tips\n",
    "\n",
    "This section provides a list of all the tricks\n",
    "\n",
    "https://towardsdatascience.com/pandas-and-python-tips-and-tricks-for-data-science-and-data-analysis-1b1e05b7d93a\n",
    "\n",
    "## 1. 𝗖𝗿𝗲𝗮𝘁𝗲 𝗮 𝗻𝗲𝘄 𝗰𝗼𝗹𝘂𝗺𝗻 𝗳𝗿𝗼𝗺 𝗺𝘂𝗹𝘁𝗶𝗽𝗹𝗲 𝗰𝗼𝗹𝘂𝗺𝗻𝘀 𝗶𝗻 𝘆𝗼𝘂𝗿 𝗱𝗮𝘁𝗮𝗳𝗿𝗮𝗺𝗲.\n",
    " \n",
    "✅ 𝙖𝙥𝙥𝙡𝙮 and 𝙡𝙖𝙢𝙗𝙙𝙖 can help you easily apply whatever logic to your columns using the following format:\n",
    "\n",
    "𝙙𝙛[𝙣𝙚𝙬_𝙘𝙤𝙡] = 𝙙𝙛.𝙖𝙥𝙥𝙡𝙮(𝙡𝙖𝙢𝙗𝙙𝙖 𝙧𝙤𝙬: 𝙛𝙪𝙣𝙘(𝙧𝙤𝙬), 𝙖𝙭𝙞𝙨=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create the dataframe\n",
    "candidates= {\n",
    "    'Name':[\"Aida\",\"Mamadou\",\"Ismael\",\"Aicha\",\"Fatou\", \"Khalil\"],\n",
    "    'Degree':['Master','Master','Bachelor', \"PhD\", \"Master\", \"PhD\"],\n",
    "    'From':[\"Abidjan\",\"Dakar\",\"Bamako\", \"Abidjan\",\"Konakry\", \"Lomé\"],\n",
    "    'Years_exp': [2, 3, 0, 6, 4, 3],\n",
    "    'From_office(min)': [120, 95, 81, 79, 100, 34]\n",
    "          }\n",
    "candidates_df = pd.DataFrame(candidates)\n",
    "\n",
    "\"\"\"\n",
    "----------------My custom function-------------------\n",
    "\"\"\" \n",
    "def candidate_info(row):\n",
    "\n",
    "  # Select columns of interest \n",
    "  name = row.Name \n",
    "  is_from = row.From\n",
    "  year_exp = row.Years_exp\n",
    "  degree = row.Degree\n",
    "  from_office = row[\"From_office(min)\"]\n",
    "\n",
    "  # Generate the description from previous variables\n",
    "  info = f\"\"\"{name} from {is_from} holds a {degree} degree \n",
    "              with {year_exp} year(s) experience \n",
    "              and lives {from_office} from the office\"\"\"\n",
    "\n",
    "  return info\n",
    "\n",
    "\"\"\"\n",
    "-------Application of the function to the data ------\n",
    "\"\"\"\n",
    "candidates_df[\"Description\"] = candidates_df.apply(lambda row: candidate_info(row), axis=1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Преобразование категориальных данных в числовые\n",
    "\n",
    "Этот процесс в основном может происходить на этапе разработки функций. Некоторые из его преимуществ следующие:\n",
    "\n",
    "- выявление выбросов, недостоверных и отсутствующих значений в данных.\n",
    "\n",
    "- уменьшение вероятности перебора путем создания более надежных моделей.\n",
    "\n",
    "➡ Используйте эти две функции из Pandas в зависимости от ваших потребностей. Примеры приведены на изображении ниже.\n",
    "\n",
    "1️⃣ .𝙘𝙪𝙩() для конкретного определения краев бина.\n",
    "\n",
    "Прикол, что очень важна настройа этого инструмента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Degree</th>\n",
       "      <th>From</th>\n",
       "      <th>Years_exp</th>\n",
       "      <th>From_office(min)</th>\n",
       "      <th>Description</th>\n",
       "      <th>Seniority</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aida</td>\n",
       "      <td>Master</td>\n",
       "      <td>Abidjan</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>Aida from Abidjan holds a Master degree \\n    ...</td>\n",
       "      <td>Mid level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mamadou</td>\n",
       "      <td>Master</td>\n",
       "      <td>Dakar</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>Mamadou from Dakar holds a Master degree \\n   ...</td>\n",
       "      <td>Mid level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ismael</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Bamako</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>Ismael from Bamako holds a Bachelor degree \\n ...</td>\n",
       "      <td>Entry level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aicha</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Abidjan</td>\n",
       "      <td>6</td>\n",
       "      <td>79</td>\n",
       "      <td>Aicha from Abidjan holds a PhD degree \\n      ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fatou</td>\n",
       "      <td>Master</td>\n",
       "      <td>Konakry</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>Fatou from Konakry holds a Master degree \\n   ...</td>\n",
       "      <td>Senior level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Khalil</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Lomé</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>Khalil from Lomé holds a PhD degree \\n        ...</td>\n",
       "      <td>Mid level</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name    Degree     From  Years_exp  From_office(min)  \\\n",
       "0     Aida    Master  Abidjan          2               120   \n",
       "1  Mamadou    Master    Dakar          3                95   \n",
       "2   Ismael  Bachelor   Bamako          0                81   \n",
       "3    Aicha       PhD  Abidjan          6                79   \n",
       "4    Fatou    Master  Konakry          4               100   \n",
       "5   Khalil       PhD     Lomé          3                34   \n",
       "\n",
       "                                         Description     Seniority  \n",
       "0  Aida from Abidjan holds a Master degree \\n    ...     Mid level  \n",
       "1  Mamadou from Dakar holds a Master degree \\n   ...     Mid level  \n",
       "2  Ismael from Bamako holds a Bachelor degree \\n ...   Entry level  \n",
       "3  Aicha from Abidjan holds a PhD degree \\n      ...           NaN  \n",
       "4  Fatou from Konakry holds a Master degree \\n   ...  Senior level  \n",
       "5  Khalil from Lomé holds a PhD degree \\n        ...     Mid level  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seniority = ['Entry level', 'Mid level', 'Senior level']\n",
    "seniority_bins = [0, 1, 3, 5]\n",
    "candidates_df['Seniority'] = pd.cut(candidates_df['Years_exp'],\n",
    "                                    bins=seniority_bins, \n",
    "                                    labels=seniority, \n",
    "                                    include_lowest=True)\n",
    "\n",
    "candidates_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2️⃣ .𝙦𝙘𝙪𝙩() для разделения данных на бины одинакового размера.\n",
    "\n",
    "Он использует базовые процентили распределения данных, а не края бинов. ( сам считает катерогии и типа если 4 категории,то от максимума смотрит в процентнорм соотношении )\n",
    "\n",
    "𝙎𝙘𝙚𝙣𝙖𝙧𝙞𝙤: классифицировать время работы кандидатов на 𝙜𝙤𝙤𝙙, 𝙖𝙘𝙘𝙚𝙥𝙩𝙖𝙗𝙡𝙚 или 𝙩𝙤𝙤𝙤 𝙡𝙤𝙣𝙜.\n",
    "\n",
    "𝙆𝙚𝙚𝙥 𝙞𝙣 𝙢𝙞𝙣𝙙 💡\n",
    "\n",
    "- When using .𝙘𝙪𝙩(): a number of bins = number of labels + 1.\n",
    "\n",
    "- When using .𝙦𝙘𝙪𝙩(): a number of bins = number of labels.\n",
    "\n",
    "- With .𝙘𝙪𝙩(): set 𝙞𝙣𝙘𝙡𝙪𝙙𝙚_𝙡𝙤𝙬𝙚𝙨𝙩=𝙏𝙧𝙪𝙚, otherwise, the lowest value will be converted to NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Degree</th>\n",
       "      <th>From</th>\n",
       "      <th>Years_exp</th>\n",
       "      <th>From_office(min)</th>\n",
       "      <th>Description</th>\n",
       "      <th>Seniority</th>\n",
       "      <th>Commute_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aida</td>\n",
       "      <td>Master</td>\n",
       "      <td>Abidjan</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>Aida from Abidjan holds a Master degree \\n    ...</td>\n",
       "      <td>Mid level</td>\n",
       "      <td>too long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mamadou</td>\n",
       "      <td>Master</td>\n",
       "      <td>Dakar</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>Mamadou from Dakar holds a Master degree \\n   ...</td>\n",
       "      <td>Mid level</td>\n",
       "      <td>acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ismael</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>Bamako</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>Ismael from Bamako holds a Bachelor degree \\n ...</td>\n",
       "      <td>Entry level</td>\n",
       "      <td>acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aicha</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Abidjan</td>\n",
       "      <td>6</td>\n",
       "      <td>79</td>\n",
       "      <td>Aicha from Abidjan holds a PhD degree \\n      ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fatou</td>\n",
       "      <td>Master</td>\n",
       "      <td>Konakry</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>Fatou from Konakry holds a Master degree \\n   ...</td>\n",
       "      <td>Senior level</td>\n",
       "      <td>too long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Khalil</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Lomé</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>Khalil from Lomé holds a PhD degree \\n        ...</td>\n",
       "      <td>Mid level</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name    Degree     From  Years_exp  From_office(min)  \\\n",
       "0     Aida    Master  Abidjan          2               120   \n",
       "1  Mamadou    Master    Dakar          3                95   \n",
       "2   Ismael  Bachelor   Bamako          0                81   \n",
       "3    Aicha       PhD  Abidjan          6                79   \n",
       "4    Fatou    Master  Konakry          4               100   \n",
       "5   Khalil       PhD     Lomé          3                34   \n",
       "\n",
       "                                         Description     Seniority  \\\n",
       "0  Aida from Abidjan holds a Master degree \\n    ...     Mid level   \n",
       "1  Mamadou from Dakar holds a Master degree \\n   ...     Mid level   \n",
       "2  Ismael from Bamako holds a Bachelor degree \\n ...   Entry level   \n",
       "3  Aicha from Abidjan holds a PhD degree \\n      ...           NaN   \n",
       "4  Fatou from Konakry holds a Master degree \\n   ...  Senior level   \n",
       "5  Khalil from Lomé holds a PhD degree \\n        ...     Mid level   \n",
       "\n",
       "  Commute_level  \n",
       "0      too long  \n",
       "1    acceptable  \n",
       "2    acceptable  \n",
       "3          good  \n",
       "4      too long  \n",
       "5          good  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commute_time_labels = [\"good\", \"acceptable\", \"too long\"]\n",
    "candidates_df[\"Commute_level\"] = pd.qcut(\n",
    "                                candidates_df[\"From_office(min)\"],\n",
    "                                q = 3, \n",
    "                                labels=commute_time_labels\n",
    "                                )\n",
    "candidates_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Выбор строк из фрейма данных Pandas на основе значений столбца(ов)\n",
    "   \n",
    "➡ используйте функцию .𝙦𝙪𝙚𝙧𝙮(), указав условие фильтрации.\n",
    "\n",
    "➡ выражение фильтрации может содержать любые операторы (<, >, ==, != и т.д.)\n",
    "\n",
    "➡ используйте знак @̷ для использования переменной в выражении.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Degree</th>\n",
       "      <th>From</th>\n",
       "      <th>Years_exp</th>\n",
       "      <th>From_office(min)</th>\n",
       "      <th>Description</th>\n",
       "      <th>Seniority</th>\n",
       "      <th>Commute_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aida</td>\n",
       "      <td>Master</td>\n",
       "      <td>Abidjan</td>\n",
       "      <td>2</td>\n",
       "      <td>120</td>\n",
       "      <td>Aida from Abidjan holds a Master degree \\n    ...</td>\n",
       "      <td>Mid level</td>\n",
       "      <td>too long</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mamadou</td>\n",
       "      <td>Master</td>\n",
       "      <td>Dakar</td>\n",
       "      <td>3</td>\n",
       "      <td>95</td>\n",
       "      <td>Mamadou from Dakar holds a Master degree \\n   ...</td>\n",
       "      <td>Mid level</td>\n",
       "      <td>acceptable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aicha</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Abidjan</td>\n",
       "      <td>6</td>\n",
       "      <td>79</td>\n",
       "      <td>Aicha from Abidjan holds a PhD degree \\n      ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Degree     From  Years_exp  From_office(min)  \\\n",
       "0     Aida  Master  Abidjan          2               120   \n",
       "1  Mamadou  Master    Dakar          3                95   \n",
       "3    Aicha     PhD  Abidjan          6                79   \n",
       "\n",
       "                                         Description  Seniority Commute_level  \n",
       "0  Aida from Abidjan holds a Master degree \\n    ...  Mid level      too long  \n",
       "1  Mamadou from Dakar holds a Master degree \\n   ...  Mid level    acceptable  \n",
       "3  Aicha from Abidjan holds a PhD degree \\n      ...        NaN          good  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all the candidates with a Master degree\n",
    "ms_candidates = candidates_df.query(\"Degree == 'Master'\")\n",
    "ms_candidates\n",
    "\n",
    "# Get non bachelor candidates\n",
    "no_bs_candidates = candidates_df.query(\"Degree != 'Bachelor'\")\n",
    "\n",
    "# Get values from list\n",
    "list_locations = [\"Abidjan\", \"Dakar\"]\n",
    "candiates = candidates_df.query(\"From in @list_locations\")\n",
    "candiates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Работа с zip-файлами\n",
    "\n",
    "Иногда бывает полезно читать и записывать файлы .zip, не извлекая их с локального диска. Ниже приведен пример."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'spam.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Check the files sizes\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mos\u001b[39;00m \u001b[39mimport\u001b[39;00m path\n\u001b[0;32m---> 13\u001b[0m path\u001b[39m.\u001b[39;49mgetsize(\u001b[39m'\u001b[39;49m\u001b[39mspam.csv\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m/\u001b[39m path\u001b[39m.\u001b[39mgetsize(\u001b[39m'\u001b[39m\u001b[39mspam.csv.zip\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39m------------ READ ZIP FILES -----------\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39m# Case 1: read a single zip file \u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/genericpath.py:50\u001b[0m, in \u001b[0;36mgetsize\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgetsize\u001b[39m(filename):\n\u001b[1;32m     49\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Return the size of a file, reported by os.stat().\"\"\"\u001b[39;00m\n\u001b[0;32m---> 50\u001b[0m     \u001b[39mreturn\u001b[39;00m os\u001b[39m.\u001b[39;49mstat(filename)\u001b[39m.\u001b[39mst_size\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'spam.csv'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "------------ WRITE ZIP FILES -----------\n",
    "\"\"\"\n",
    "# Read data from internet\n",
    "url = \"https://raw.githubusercontent.com/keitazoumana/Fastapi-tutorial/master/data/spam.csv\"\n",
    "spam_data = pd.read_csv(url, encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Save it as a zip file\n",
    "spam_data.to_csv(\"spam.csv.zip\", compression=\"zip\")\n",
    "\n",
    "# Check the files sizes\n",
    "from os import path\n",
    "path.getsize('spam.csv') / path.getsize('spam.csv.zip')\n",
    "\"\"\"\n",
    "------------ READ ZIP FILES -----------\n",
    "\"\"\"\n",
    "# Case 1: read a single zip file \n",
    "candidate_df_unzip = pd.read_csv('candidates.csv.zip', compression='zip')\n",
    "\n",
    "# Case 2: read a file from a folder\n",
    "from zipfile import ZipFile\n",
    "\n",
    "# Read the file from a zip folder\n",
    "sales_df = pd.read_csv(ZipFile(\"data.zip\").open('data/sales_df.csv'))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Выберите 𝗮 𝘀𝘂𝗯𝘀𝗲𝘁 𝗼𝗳 𝘆𝗼𝘂𝗿 𝗣𝗮𝗻𝗱𝗮𝘀 𝗱𝗮𝘁𝗮𝗳𝗿𝗮𝗺𝗲 𝘄𝗶𝘁𝗵 𝘀𝗽𝗲𝗰𝗶𝗳𝗶𝗰 𝗰𝗼𝗹𝘂𝗺𝗻 𝘁𝘆𝗽𝗲𝘀.\n",
    "\n",
    "Вы можете использовать функцию 𝙨𝙚𝙡𝙚𝙘𝙩_𝙙𝙩𝙮𝙥𝙚𝙨. Она принимает два основных параметра: 𝚒𝚗𝚌𝚕𝚞𝚍𝚎 𝚊𝚗𝚍 𝚎𝚡𝚌𝚕𝚞𝚍𝚎.\n",
    "\n",
    "- 𝚍𝚏.𝚜𝚎𝚕𝚎𝚌𝚝_𝚍𝚝𝚢𝚙𝚎𝚜(𝚒𝚗𝚌𝚕𝚞𝚍𝚎 = ['𝚝𝚢𝚙𝚎_𝟷', '𝚝𝚢𝚙𝚎_𝟸', ... '𝚝𝚢𝚙𝚎_𝚗']) означает, что я хочу получить подмножество моего фрейма данных со столбцами 𝚝𝚢𝚙𝚎_𝟷, 𝚝𝚢𝚙𝚎_𝟸, ..., 𝚝𝚢𝚙𝚎_𝚗.\n",
    "\n",
    "- 𝚍𝚏.𝚜𝚎𝚕𝚎𝚌𝚝_𝚍𝚝𝚢𝚙𝚎𝚜(𝚎𝚡𝚌𝚕𝚞𝚍𝚎 = ['𝚝𝚢𝚙𝚎_𝟷', '𝚝𝚢𝚙𝚎_𝟸', ... '𝚝𝚢𝚙𝚎_𝚗']) означает, что я хочу получить подмножество моего фрейма данных БЕЗ столбцов 𝚝𝚢𝚙𝚎_𝟷, 𝚝𝚢𝚙𝚎_𝟸,..., 𝚝𝚢𝚙𝚎_𝚗.\n",
    "\n",
    "✨ Ниже приведена иллюстрация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/candidates_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Read my dataset\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m candidates_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m./data/candidates_data.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Check the data columns' types\u001b[39;00m\n\u001b[1;32m      5\u001b[0m candidates_df\u001b[39m.\u001b[39mdtypes\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/candidates_data.csv'"
     ]
    }
   ],
   "source": [
    "# Read my dataset\n",
    "candidates_df = pd.read_csv(\"./data/candidates_data.csv\")\n",
    "\n",
    "# Check the data columns' types\n",
    "candidates_df.dtypes\n",
    "\n",
    "# Only select columns of type \"object\" & \"datetime\"\n",
    "candidates_df.select_dtypes(include = [\"object\", \"datetime64\"])\n",
    "\n",
    "# Exclude columns of type \"datetime\" & \"int\"\n",
    "candidates_df.select_dtypes(exclude = [\"int64\", \"datetime64\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Удаление комментариев из столбца датафрейма Pandas\n",
    "\n",
    "Представьте, что я хочу очистить эти данные (candidates.csv), удалив комментарии из столбца даты подачи заявки. Это можно сделать на лету при загрузке датафрейма pandas с помощью параметра 𝙘𝙤𝙢𝙢𝙚𝙣𝙩, как показано ниже:\n",
    "\n",
    "➡ 𝚌𝚕𝚎𝚊𝚗_𝚍𝚊𝚝𝚊 = 𝚙𝚍.𝚛𝚎𝚊𝚍_𝚌𝚜𝚟(𝚙𝚊𝚝𝚑_𝚝𝚘_𝚍𝚊𝚝𝚊, 𝙘𝙤𝙢𝙢𝙚𝙣𝙩='𝚜𝚢𝚖𝚋𝚘𝚕')\n",
    "\n",
    "В моем случае 𝙘𝙤𝙢𝙢𝙚𝙣𝙩='#', но это может быть любой другой символ (|, / и т.д.) в зависимости от вашего случая. Иллюстрацией может служить первый сценарий.\n",
    "\n",
    "✋🏽 Подождите, а если я хочу создать новый столбец для этих комментариев и при этом удалить их из столбца даты подачи заявки? Иллюстрация - второй сценарий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read my messy dataset\n",
    "messy_df = pd.read_csv(\"./data/candidates_data.csv\")\n",
    "\n",
    "# FIRST SCENARIO -> REMOVE COMMENTS\n",
    "clean_df = pd.read_csv(\"./data/candidates_data.csv\", comment='#')\n",
    "\n",
    "# SECOND SCENARIO -> CREATE NEW COLUMN FOR COMMENTS\n",
    "messy_df[['application_date', 'comment']] = messy_df['application_date'].str.split('#', 1, expand=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Печать кадра данных Pandas в табличном формате из консоли\n",
    "\n",
    "❌ Нет, применение функции 𝚙𝚛𝚒𝚗𝚝() к кадру данных pandas не всегда выводит результат, который легко читать, особенно для кадров данных с несколькими столбцами.\n",
    "\n",
    "✅ Если вы хотите получить красивый табличный вывод, удобный для консольного использования.\n",
    "Используйте функцию .𝚝𝚘_𝚜𝚝𝚛𝚒𝚗𝚐(), как показано ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Rank                      Name Platform    Year         Genre Publisher  \\\n",
      "0     1                Wii Sports      Wii  2006.0        Sports  Nintendo   \n",
      "1     2         Super Mario Bros.      NES  1985.0      Platform  Nintendo   \n",
      "2     3            Mario Kart Wii      Wii  2008.0        Racing  Nintendo   \n",
      "3     4         Wii Sports Resort      Wii  2009.0        Sports  Nintendo   \n",
      "4     5  Pokemon Red/Pokemon Blue       GB  1996.0  Role-Playing  Nintendo   \n",
      "\n",
      "   NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales  \n",
      "0     41.49     29.02      3.77         8.46         82.74  \n",
      "1     29.08      3.58      6.81         0.77         40.24  \n",
      "2     15.85     12.88      3.79         3.31         35.82  \n",
      "3     15.75     11.01      3.28         2.96         33.00  \n",
      "4     11.27      8.89     10.22         1.00         31.37  \n",
      "   Rank                      Name Platform    Year         Genre Publisher  NA_Sales  EU_Sales  JP_Sales  Other_Sales  Global_Sales\n",
      "0     1                Wii Sports      Wii  2006.0        Sports  Nintendo     41.49     29.02      3.77         8.46         82.74\n",
      "1     2         Super Mario Bros.      NES  1985.0      Platform  Nintendo     29.08      3.58      6.81         0.77         40.24\n",
      "2     3            Mario Kart Wii      Wii  2008.0        Racing  Nintendo     15.85     12.88      3.79         3.31         35.82\n",
      "3     4         Wii Sports Resort      Wii  2009.0        Sports  Nintendo     15.75     11.01      3.28         2.96         33.00\n",
      "4     5  Pokemon Red/Pokemon Blue       GB  1996.0  Role-Playing  Nintendo     11.27      8.89     10.22         1.00         31.37\n"
     ]
    }
   ],
   "source": [
    "data_URL = \"https://raw.githubusercontent.com/keitazoumana/Experimentation-Data/main/vgsales.csv\" \n",
    "\n",
    "# Read your dataframe\n",
    "video_game_data = pd.read_csv(data_URL)\n",
    "\n",
    "\"\"\"\n",
    "Printing without to_string() function\n",
    "\"\"\"\n",
    "print(video_game_data.head())\n",
    "\n",
    "\"\"\"\n",
    "Printing with to_string() function\n",
    "\"\"\"\n",
    "print(video_game_data.head().to_string())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Выделение точек данных в Pandas\n",
    "Применение цветов к рамке данных pandas может быть хорошим способом выделения определенных точек данных для быстрого анализа.\n",
    "\n",
    "✅ Здесь на помощь приходит модуль 𝚙𝚊𝚗𝚍𝚊𝚜.𝚜𝚝𝚢𝚕𝚎. Он имеет множество функций, но не ограничивается следующими:\n",
    "\n",
    "✨ 𝚍𝚏.𝚜𝚝𝚢𝚕𝚎.𝚑𝚒𝚐𝚑𝚕𝚒𝚐𝚑𝚝_𝚖𝚊𝚡() для присвоения цвета максимальному значению каждого столбца.\n",
    "\n",
    "✨ 𝚍𝚏.𝚜𝚝𝚢𝚕𝚎.𝚑𝚒𝚐𝚑𝚕𝚒𝚐𝚑𝚝_𝚖in() для присвоения цвета минимальному значению каждого столбца.\n",
    "\n",
    "✨ 𝚍𝚏.𝚜𝚝𝚢𝚕𝚎.𝚊𝚙𝚙𝚕𝚢(𝚖𝚢_𝚌𝚞𝚜𝚝𝚘𝚖_𝚏𝚞𝚗𝚌𝚝𝚒𝚘𝚗) для применения вашей пользовательской функции к кадру данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_c0ada_row0_col1, #T_c0ada_row0_col2, #T_c0ada_row3_col1, #T_c0ada_row3_col2, #T_c0ada_row4_col1, #T_c0ada_row4_col2 {\n",
       "  background-color: #C4DE6B;\n",
       "  color: white;\n",
       "}\n",
       "#T_c0ada_row1_col1, #T_c0ada_row1_col2, #T_c0ada_row2_col1, #T_c0ada_row2_col2 {\n",
       "  background-color: #C4606B;\n",
       "  color: white;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_c0ada\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_c0ada_level0_col0\" class=\"col_heading level0 col0\" >Salary</th>\n",
       "      <th id=\"T_c0ada_level0_col1\" class=\"col_heading level0 col1\" >Height</th>\n",
       "      <th id=\"T_c0ada_level0_col2\" class=\"col_heading level0 col2\" >weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_c0ada_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_c0ada_row0_col0\" class=\"data row0 col0\" >100000.200000</td>\n",
       "      <td id=\"T_c0ada_row0_col1\" class=\"data row0 col1\" >6.500000</td>\n",
       "      <td id=\"T_c0ada_row0_col2\" class=\"data row0 col2\" >185.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0ada_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_c0ada_row1_col0\" class=\"data row1 col0\" >95000.900000</td>\n",
       "      <td id=\"T_c0ada_row1_col1\" class=\"data row1 col1\" >5.200000</td>\n",
       "      <td id=\"T_c0ada_row1_col2\" class=\"data row1 col2\" >105.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0ada_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_c0ada_row2_col0\" class=\"data row2 col0\" >103000.200000</td>\n",
       "      <td id=\"T_c0ada_row2_col1\" class=\"data row2 col1\" >5.590000</td>\n",
       "      <td id=\"T_c0ada_row2_col2\" class=\"data row2 col2\" >110.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0ada_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_c0ada_row3_col0\" class=\"data row3 col0\" >65984.100000</td>\n",
       "      <td id=\"T_c0ada_row3_col1\" class=\"data row3 col1\" >6.700000</td>\n",
       "      <td id=\"T_c0ada_row3_col2\" class=\"data row3 col2\" >190.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_c0ada_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_c0ada_row4_col0\" class=\"data row4 col0\" >150987.080000</td>\n",
       "      <td id=\"T_c0ada_row4_col1\" class=\"data row4 col1\" >6.920000</td>\n",
       "      <td id=\"T_c0ada_row4_col2\" class=\"data row4 col2\" >200.590000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x105a7a460>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_info = {\n",
    "    \"Salary\": [100000.2, 95000.9, 103000.2, 65984.1, 150987.08], \n",
    "    \"Height\": [6.5, 5.2, 5.59, 6.7, 6.92], \n",
    "    \"weight\": [185.23, 105.12, 110.3, 190.12, 200.59]      \n",
    "}\n",
    "my_data = pd.DataFrame(my_info)\n",
    "\n",
    "\"\"\"\n",
    "Function to highlight min and max\n",
    "\"\"\"\n",
    "\n",
    "def highlight_min_max(data_frame, min_color, max_color):\n",
    "\n",
    "  # This first line create a styler object\n",
    "  final_data = data_frame.style.highlight_max(color = max_color)\n",
    "\n",
    "  # On this second line, no need to use \".style\"\n",
    "  final_data = final_data.highlight_min(color = min_color)\n",
    "\n",
    "  return final_data\n",
    "  \n",
    "# Function to apply ORANGE to min and GREEN to max\n",
    "highlight_min_max(my_data, min_color='orange', max_color='green')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Custom function: apply RED or GREEN whether data is below or above the mean. \n",
    "\"\"\"\n",
    "def highlight_values(data_row):\n",
    "  low_value_color = \"background-color:#C4606B  ; color: white;\"\n",
    "  high_value_color = \"background-color: #C4DE6B; color: white;\"   \n",
    "  filter = data_row < data_row.mean()\n",
    "\n",
    "  return [low_value_color if low_value else high_value_color for low_value in filter]\n",
    "  \n",
    "# Application of my custom function to only 'Height' & 'weight'\n",
    "my_data.style.apply(highlight_values, subset=['Height', 'weight'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Сократите количество десятичных знаков в данных\n",
    "Иногда очень длинные десятичные значения в вашем наборе данных не дают существенной информации и могут быть болезненными 🤯 при просмотре.\n",
    "\n",
    "Поэтому вы можете преобразовать данные до 2-3 знаков после запятой, чтобы облегчить анализ.\n",
    "\n",
    "✅ Это можно сделать с помощью функции 𝚙𝚊𝚗𝚍𝚊𝚜.𝙳𝚊𝚝𝚊𝙵𝚛𝚊𝚖𝚎.𝚛𝚘𝚞𝚗𝚍(), как показано ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Salary</th>\n",
       "      <th>Height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100000.23</td>\n",
       "      <td>6.50</td>\n",
       "      <td>185.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95000.90</td>\n",
       "      <td>5.27</td>\n",
       "      <td>105.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>103000.23</td>\n",
       "      <td>5.59</td>\n",
       "      <td>110.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65984.14</td>\n",
       "      <td>6.73</td>\n",
       "      <td>190.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>150987.08</td>\n",
       "      <td>6.92</td>\n",
       "      <td>200.59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Salary  Height  weight\n",
       "0  100000.23    6.50  185.23\n",
       "1   95000.90    5.27  105.12\n",
       "2  103000.23    5.59  110.35\n",
       "3   65984.14    6.73  190.12\n",
       "4  150987.08    6.92  200.59"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_decimals_info = {\n",
    "    \"Salary\": [100000.23400000, 95000.900300, 103000.2300535, 65984.14000450, 150987.080345], \n",
    "    \"Height\": [6.501050, 5.270000, 5.5900001050, 6.730001050, 6.92100050], \n",
    "    \"weight\": [185.23000059, 105.1200099, 110.350003, 190.12000000, 200.59000000]      \n",
    "}\n",
    "\n",
    "long_decimals_df = pd.DataFrame(long_decimals_info)\n",
    "\n",
    "\"\"\"\n",
    "Format the data with 2 decimal places\n",
    "\"\"\"\n",
    "fewer_decimals_df = long_decimals_df.round(decimals=2)\n",
    "fewer_decimals_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Замена некоторых значений в кадре данных\n",
    "Вам может понадобиться заменить некоторую информацию в вашей рамке данных, чтобы сохранить ее как можно более актуальной.\n",
    "\n",
    "✅ Это можно сделать с помощью функции Pandas 𝚍𝚊𝚝𝚊𝚏𝚛𝚊𝚖𝚎.𝚛𝚎𝚙𝚕𝚊𝚌𝚎(), как показано ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_info = {\n",
    "    'Full_Name':[\"Aida Kone\",\"Mamadou Diop\",\"Ismael Camara\",\"Aicha Konate\",\n",
    "                 \"Fanta Koumare\", \"Khalil Cisse\"],\n",
    "    'degree':['Master','MS','Bachelor', \"PhD\", \"Masters\", np.nan],\n",
    "    'From':[np.nan,\"Dakar\",\"Bamako\", \"Abidjan\",\"Konakry\", \"Lomé\"],\n",
    "    'Age':[23,26,19, np.nan,25, np.nan],\n",
    "          }\n",
    "\n",
    "candidates_df = pd.DataFrame(candidates_info) \n",
    "\n",
    "\"\"\"\n",
    "Replace Masters, Master by MS\n",
    "\"\"\"\n",
    "degrees_to_replace = [\"Master\", \"Masters\"]\n",
    "candidates_df.replace(to_replace = degrees_to_replace, value = \"MS\", inplace=True)\n",
    "\n",
    "\"\"\"\n",
    "Replace all the NaN by \"Missing\"\n",
    "\"\"\"\n",
    "candidates_df.replace(to_replace=np.nan, value = \"Missing\", inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Сравнение двух фреймов данных и получение их различий\n",
    "Иногда, сравнивая два фрейма данных pandas, вы хотите не только узнать, эквивалентны ли они, но и где находится разница, если они не эквивалентны.\n",
    "\n",
    "✅ Здесь пригодится функция .𝚌𝚘𝚖𝚙𝚊𝚛𝚎().\n",
    "\n",
    "✨ Она генерирует рамку данных, показывающую столбцы с различиями рядом друг с другом. Его форма отлична от (0, 0) только в том случае, если два сравниваемых данных одинаковы.\n",
    "\n",
    "✨ Если вы хотите показать значения, которые равны, установите параметр 𝚔𝚎𝚎𝚙_𝚎𝚚𝚞𝚊𝚕 в 𝚃𝚛𝚞𝚎. В противном случае они отображаются как 𝙽𝚊𝙽."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/candidates.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mimport\u001b[39;00m assert_frame_equal\n\u001b[0;32m----> 3\u001b[0m candidates_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mdata/candidates.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      5\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mCreate a second dataframe by changing \"Full_Name\" & \"Age\" columns\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m candidates_df_test \u001b[39m=\u001b[39m candidates_df\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/candidates.csv'"
     ]
    }
   ],
   "source": [
    "from pandas.testing import assert_frame_equal\n",
    "\n",
    "candidates_df = pd.read_csv(\"data/candidates.csv\")\n",
    "\n",
    "\"\"\"\n",
    "Create a second dataframe by changing \"Full_Name\" & \"Age\" columns\n",
    "\"\"\"\n",
    "candidates_df_test = candidates_df.copy()\n",
    "candidates_df_test.loc[0, 'Full_Name'] = 'Aida Traore'\n",
    "candidates_df_test.loc[2, 'Age'] = 28\n",
    "\n",
    "\"\"\"\n",
    "Compare the two dataframes: candidates_df & candidates_df_test\n",
    "\"\"\"\n",
    "# 1. Comparison showing only unmatching values\n",
    "candidates_df.compare(candidates_df_test)\n",
    "\n",
    "# 2. Comparison including similar values\n",
    "candidates_df.compare(candidates_df_test, keep_equal=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Получение подмножества очень большого набора данных для быстрого анализа\n",
    "Иногда нам просто нужно получить подмножество очень большого набора данных для быстрого анализа. Одним из подходов может быть чтение всех данных в памяти перед получением выборки.\n",
    "\n",
    "Это может потребовать много памяти в зависимости от того, насколько велики ваши данные. Кроме того, чтение данных может занять значительное время.\n",
    "\n",
    "✅ Вы можете использовать параметр 𝚗𝚛𝚘𝚠𝚜 в функции pandas 𝚛𝚎𝚊𝚍_𝚌𝚜𝚟(), указав нужное вам количество строк.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'autotime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mload_ext\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mautotime\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# File to get sample from: Size: 261,6 MB\u001b[39;00m\n\u001b[1;32m      4\u001b[0m large_data \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdiabetes_benchmark_data.csv\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2369\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2367\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2368\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2369\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2371\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2372\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2373\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2374\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/IPython/core/magics/extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m module_str:\n\u001b[1;32m     32\u001b[0m     \u001b[39mraise\u001b[39;00m UsageError(\u001b[39m'\u001b[39m\u001b[39mMissing module name.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49mextension_manager\u001b[39m.\u001b[39;49mload_extension(module_str)\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39malready loaded\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m     36\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m extension is already loaded. To reload it, use:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m module_str)\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/IPython/core/extensions.py:76\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[39mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[39m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[39mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load_extension(module_str)\n\u001b[1;32m     77\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mModuleNotFoundError\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     \u001b[39mif\u001b[39;00m module_str \u001b[39min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/site-packages/IPython/core/extensions.py:91\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[0;34m(self, module_str)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m     90\u001b[0m     \u001b[39mif\u001b[39;00m module_str \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m sys\u001b[39m.\u001b[39mmodules:\n\u001b[0;32m---> 91\u001b[0m         mod \u001b[39m=\u001b[39m import_module(module_str)\n\u001b[1;32m     92\u001b[0m     mod \u001b[39m=\u001b[39m sys\u001b[39m.\u001b[39mmodules[module_str]\n\u001b[1;32m     93\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_load_ipython_extension(mod):\n",
      "File \u001b[0;32m~/Desktop/ITMO/my_courses/My_education/.conda/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'autotime'"
     ]
    }
   ],
   "source": [
    "%load_ext autotime\n",
    "\n",
    "# File to get sample from: Size: 261,6 MB\n",
    "large_data = \"diabetes_benchmark_data.csv\"\n",
    "\n",
    "# Sample size of interest\n",
    "sample_size = 400\n",
    "\n",
    "\"\"\"\n",
    "Approach n°1: Read all the data in memory before getting the sample \n",
    "\"\"\"\n",
    "read_whole_data = pd.read_csv(large_data)\n",
    "sample_data = read_whole_data.head(sample_size)\n",
    "\n",
    "\"\"\"\n",
    "Approach n°2: Read the sample on the fly\n",
    "\"\"\"\n",
    "read_sample = pd.read_csv(large_data, nrows=sample_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Преобразование рамки данных из широкого формата в длинный\n",
    "Иногда бывает полезно 𝚝𝚛𝚊𝚗𝚜𝚏𝚘𝚛𝚖 𝚢𝚘𝚞𝚛 𝚍𝚊𝚝𝚊𝚏𝚛𝚊𝚖𝚎 𝚏𝚛𝚘𝚖 𝚊 𝚠𝚒𝚍𝚎 𝚝𝚘 𝚊 𝚕𝚘𝚗𝚐 𝚏𝚘𝚛𝚖𝚊𝚝, который является более гибким для лучшего анализа, особенно при работе с данными временных рядов.\n",
    "\n",
    "𝙒𝙝𝙖𝙩 𝙙𝙤 𝙮𝙤𝙪 𝙢𝙚𝙖𝙣 𝙗𝙮 𝙬𝙞𝙙𝙚 & 𝙡𝙤𝙣𝙜?\n",
    "✨ Широкий формат - это когда у вас много колонок.\n",
    "✨ Длинный формат с другой стороны - это когда у вас много строк.\n",
    "\n",
    "✅ 𝙿𝚊𝚗𝚍𝚊𝚜.𝚖𝚎𝚕𝚝() - идеальный кандидат для этой задачи.\n",
    "\n",
    "Ниже приведена иллюстрация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates= {\n",
    "    'Name':[\"Aida\",\"Mamadou\",\"Ismael\",\"Aicha\"],\n",
    "    'ID': [1, 2, 3, 4],\n",
    "    '2017':[85, 87, 89, 91],\n",
    "    '2018':[96, 98, 100, 102],\n",
    "    '2019':[100, 102, 106, 106],\n",
    "    '2020':[89, 95, 98, 100],\n",
    "    '2021':[94, 96, 98, 100],\n",
    "    '2022':[100, 104, 104, 107],\n",
    "          }\n",
    "\"\"\"\n",
    "Data in wide format\n",
    "\"\"\"\n",
    "salary_data = pd.DataFrame(candidates)\n",
    "\n",
    "\"\"\"\n",
    "Transformation into the long format\n",
    "\"\"\"\n",
    "long_format_data = salary_data.melt(id_vars=['Name', 'ID'], \n",
    "                                    var_name='Year', value_name='Salary(k$)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Уменьшение размера кадра данных Pandas за счет игнорирования индекса\n",
    "Знаете ли вы, что можно уменьшить размер фрейма данных Pandas, игнорируя индекс при его сохранении?\n",
    "\n",
    "✅ Что-то вроде 𝚒𝚗𝚍𝚎𝚡 = 𝙵𝚊𝚕𝚜𝚎 при сохранении файла.\n",
    "\n",
    "Ниже приведена иллюстрация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525040 -rw-r--r--  1 nikitav  staff   249M Apr  4 15:50 large_data_with_index.csv\n",
      "460208 -rw-r--r--  1 nikitav  staff   221M Apr  4 15:50 large_data_without_index.csv\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://raw.githubusercontent.com/keitazoumana/Experimentation-Data/main/diabetes.csv\"\n",
    "data = pd.read_csv(URL)\n",
    "\n",
    "# Create large data by repeating each row 10000 times\n",
    "large_data = data.loc[data.index.repeat(10000)]\n",
    "\n",
    "\"\"\"\n",
    "SAVE WITH INDEX\n",
    "\"\"\"\n",
    "large_data.to_csv(\"large_data_with_index.csv\")\n",
    "\n",
    "# Check the size of the file \n",
    "!ls -GFlash large_data_with_index.csv\n",
    "\n",
    "\"\"\"\n",
    "SAVE WITHOUT INDEX\n",
    "\"\"\"\n",
    "large_data.to_csv(\"large_data_without_index.csv\", index = False)\n",
    "\n",
    "# Check the size of the file \n",
    "!ls -GFlash large_data_without_index.csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Parquet вместо CSV\n",
    "Очень часто я не просматриваю вручную 👀 содержимое CSV или Excel файла, который будет использоваться Pandas для дальнейшего анализа.\n",
    "\n",
    "Если это ваш случай, возможно, вам не стоит больше использовать .CSV и подумать о лучшем варианте.\n",
    "\n",
    "Особенно если вас волнует только\n",
    "\n",
    "✨ Скорость обработки\n",
    "\n",
    "✨ Скорость сохранения и загрузки\n",
    "\n",
    "✨ Место на диске, занимаемое рамкой данных\n",
    "\n",
    "✅ В этом случае формат .𝙥𝙖𝙧𝙦𝙪𝙚𝙩 является лучшим вариантом, как показано ниже.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": [
    "URL = \"https://raw.githubusercontent.com/keitazoumana/Experimentation-Data/main/diabetes.csv\"\n",
    "data = pd.read_csv(URL)\n",
    "\n",
    "# Create large data for experimentation by repeating each row 20.000 times\n",
    "exp_data = data.loc[data.index.repeat(20000)]\n",
    "\n",
    "\"\"\"\n",
    "EXPERIMENT WITH .CSV FORMAT\n",
    "\"\"\"\n",
    "# Write Time\n",
    "%%time \n",
    "exp_data.to_csv(\"exp_data.csv\", index=False)\n",
    "\n",
    "# Read Time\n",
    "%%time\n",
    "csv_data = pd.read_csv(\"exp_data.csv\")\n",
    "\n",
    "# File Size\n",
    "!ls -GFlash exp_data.csv\n",
    "\n",
    "\"\"\"\n",
    "EXPERIMENT WITH .PARQUET FORMAT\n",
    "\"\"\"\n",
    "# Write Time\n",
    "%%time \n",
    "exp_data.to_parquet('exp_data.parquet')\n",
    "# Read Time\n",
    "%%time \n",
    "parquet_data = pd.read_parquet('exp_data.parquet')\n",
    "# File Size\n",
    "!ls -GFlash exp_data.parquet "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Преобразование рамки данных в уценку\n",
    "Всегда лучше вывести рамку данных в виде, облегчающем ее понимание.\n",
    "\n",
    "✅ Один из способов сделать это - преобразовать ее в формат уценки с помощью функции .`𝚝𝚘_𝚖𝚊𝚛𝚔𝚍𝚘𝚠𝚗()`.\n",
    "\n",
    "💡 Ниже приведена иллюстрация."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Форматирование столбца Дата-Время\n",
    "При загрузке фреймов данных Pandas столбцы даты представляются как 𝗼𝗯𝗷𝗲𝗰𝘁 по умолчанию, что не является ❌ правильным форматом даты.\n",
    "\n",
    "✅ Вы можете указать целевой столбец в аргументе 𝗽𝗮𝗿𝘀𝗲_𝗱𝗮𝘁𝗲𝘀, чтобы получить правильный тип столбца."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
